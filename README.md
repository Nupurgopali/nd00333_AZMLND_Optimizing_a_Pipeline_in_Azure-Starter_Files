# Optimizing an ML Pipeline in Azure

## Overview
This project is part of the Udacity Azure ML Nanodegree.
In this project, we build and optimize an Azure ML pipeline using the Python SDK and a provided Scikit-learn model.
This model is then compared to an Azure AutoML run.

## Summary
**In 1-2 sentences, explain the problem statement: e.g "This dataset contains data about... we seek to predict..."**: The data consists of information about customers of a bank and it contains 40 attributes about them and using these attributes the model had to classify if the customer will make a deposit or not.

**In 1-2 sentences, explain the solution: e.g. "The best performing model was a ..."**: The ID of the best run model was voting ensemble or stacking ensemble with accuracy 91.7%.

## Scikit-learn Pipeline
**Explain the pipeline architecture, including data, hyperparameter tuning, and classification algorithm.**
For this project I used bank_market.csv file which contains the needed data to classify the customers into two groups whether they will make a fixed deposit or not
The target column was 'y'.
For this I had to make some changes in the train.py and udacity-project.ipynb. In train.py ,I add the data using TabularDataset and then cleaned it using clean_data function
Then using test_train_split function of sckitlearn I splitted the dataset into training and testing set that were then given as input to then logistic regression model.

In udacity-project.ipynb,I initially finished the workspace and experiment configurations,then I created a compute cluster.Then for parameter tunning I was asked to use
RandomParameterSampling and tune "--C" and "--max_iter" features.To tune these two parameters I used a list that contains 3 numbers from which the model can select the most sui
table value.Then I was asked to use BanditPolicy as the early stop policy where I kept evaluation_interval=1.Then I finished and ran my hyperdriveconfig file.

After this,I loaded the dataset in the notebook using the url and then cleaned the dataset.After that I created the automl config,ran it and saved the best run model.
**What are the benefits of the parameter sampler you chose?**
I chose RandomParametSampler for this project as it supports discrete and continuous hyperparameters. It supports early termination of low-performance runs.
**What are the benefits of the early stopping policy you chose?**
For early stopping I used BanditPolicy that terminates runs where the primary metric is not within the specified slack factor/slack amount compared to the best performing run.
This inturns saves time and computational resources.
## AutoML
**In 1-2 sentences, describe the model and hyperparameters generated by AutoML.**
In Automl the hyperparameters used were 'classification' for task,'accuracy'for metrics,label column was 'y' and the number of cross validation were 5/
## Pipeline comparison
**Compare the two models and their performance. What are the differences in accuracy? In architecture? If there was a difference, why do you think there was one?**
Here's a snapshot of one run model along with it's details:
![image](https://user-images.githubusercontent.com/53776611/99043899-eb7b4f00-25b4-11eb-8aa4-4b0da5226015.png)
Another snapshot of a different run model with it's details:
![image](https://user-images.githubusercontent.com/53776611/99044034-21203800-25b5-11eb-9312-9a9187cb1771.png)
From these two images we can observe difference ithe accuracy,that is due to difference in the architecture of both the models.They analysed the input data
and pattern in a different manner and hence gave difference output.

## Future work
**What are some areas of improvement for future experiments? Why might these improvements help the model?**
In case of hyperdrive config,few changes that can be made :
1.Use of different hyperparameters,apart from "--C" and "max_iter".
2.Changing the early stop policy and using other policy apart from bandit,might improve the accuracy.
Apart from these changes, with more data it will allow the model to get a clearn pattern among the data and hence it will make better ppredictions.
We can even shift to a neural net and try to get the accuracy to the prediction, it might be better than our exisiting best model i.e. voting ensemble.

